{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5eabb34cbd5b7b2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/miquelmn/aa_2526/blob/main/06_Transfer/AlexNet_Transfer.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272d21b93244ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b4be692d2233a",
   "metadata": {},
   "source": [
    "# Models ja existents i *transfer learning*\n",
    "\n",
    "En aquesta pràctica, aprofundirem en la classificació d’imatges amb xarxes neuronals convolucionals (CNNs), però amb un enfocament diferent al de la sessió anterior. Mentre que anteriorment vàrem construir CNNs des de zero per comprendre la seva estructura bàsica, aquest cop treballarem amb un model de CNN preentrenat: **AlexNet**. Els objectius són:\n",
    "\n",
    "- **Comprendre i utilitzar un model existent**: en aquest cas, AlexNet, un model ja entrenat sobre un gran conjunt de dades.\n",
    "- **Transfer Learning**: aprendre com aprofitar els coneixements d’una xarxa preentrenada i adaptar-la per resoldre una nova tasca.\n",
    "- **Càrrega de conjunts de dades d’imatges locals**: aplicar el processament d’imatges i la càrrega de dades des de l’ordinador.\n",
    "\n",
    "Aquest enfocament ajuda a optimitzar l’entrenament i és especialment útil quan es disposa de pocs recursos computacionals o un conjunt de dades més reduït.\n",
    "\n",
    "### AlexNet\n",
    "\n",
    "AlexNet és una xarxa que va establir un nou estàndard en visió per computador gràcies a la seva capacitat de reconeixement en múltiples categories. La seva estructura, composta de capes convolucionals i de max-pooling, amb capes totalment connectades al final, és una referència en el camp de les CNNs.\n",
    "\n",
    "Aquest cop, usarem AlexNet com a punt de partida, sense construir el model des de zero, per veure com es poden reutilitzar i adaptar les seves característiques apreses per a nous conjunts de dades.\n",
    "\n",
    "### Què és el Transfer Learning?\n",
    "\n",
    "El Transfer Learning és una tècnica que permet aprofitar les xarxes preentrenades (com AlexNet) per a una nova tasca. La xarxa es modifica per adaptar-la a les noves classes del conjunt de dades que volem classificar, fent ús de les característiques generals ja apreses en l’entrenament inicial (vores, textures, etc.).\n",
    "\n",
    "Aquest process es pot fer de dues maneres. La primera és el que també rep el nom de **fine-tunning**:\n",
    "- Congelarem les primeres capes del model per conservar les característiques generals apreses.\n",
    "- Modificarem i entrenarem només les capes finals per adaptar-les a les noves classes, fent que el model s’ajusti de forma ràpida i amb menys dades.\n",
    "\n",
    "La segona, que anomenam també com la categoria general **transfer learning**:\n",
    "\n",
    "- Congelarem les capes de l'extractor de característiques del model per conservar les característiques generals apreses.\n",
    "- Afegir un nou classificador ``MLP`` i entrenar-ho de 0.\n",
    "\n",
    "\n",
    "Aquest procediment permetrà entendre com es pot utilitzar una xarxa ja existent per resoldre tasques específiques sense haver de construir ni entrenar un model completament des de zero.\n",
    "\n",
    "### Guia de la Pràctica\n",
    "\n",
    "En aquest notebook treballarem per:\n",
    "\n",
    " 1. Carregar i preparar un conjunt d’imatges des de l’ordinador.\n",
    " 2. Utilitzar el model AlexNet preentrenat i aplicar transfer learning per ajustar-lo a noves categories.\n",
    " 3. Analitzar el rendiment del model i visualitzar els resultats.\n",
    "\n",
    "## Començam\n",
    "\n",
    "Primer de tot, com sempre, hem d'obtenir les dades. Aquesta sessió la farem amb el conjunt de dades [Tiny ImageNet](https://www.kaggle.com/c/tiny-imagenet/data?select=train.images.zip). \n",
    "\n",
    "Aquest conjunt de dades es defineix en la seva plana de la forma següent:\n",
    "\n",
    "> MicroImageNet classification challenge is similar to the classification challenge in the full ImageNet ILSVRC. MicroImageNet contains 200 classes for training. Each class has 500 images. The test set contains 10,000 images. All images are 64x64 colored ones.\n",
    "\n",
    "Aquesta vegada no farem feina amb un conjunt de dades ja existents a ``torchvision`` sinó que nosaltres farem la gestió des de 0. Per tant i primer de tot descarregarem les dades. Per fer-ho podem trobar el conjunt de dades a la següent plana (http://cs231n.stanford.edu/tiny-imagenet-200.zip).\n",
    "\n",
    "Alternativament també podem emprar l'eina ``wget`` així:\n",
    "\n",
    "```\n",
    "wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "```\n",
    "\n",
    "Una vegada que hem descarregat les dades les podem descomprimir i finalment comença a fer-hi feina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040a135483ff08e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: '../tiny-imagenet-200/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      5\u001b[39m SAMPLE = \u001b[32m50000\u001b[39m\n\u001b[32m      7\u001b[39m transform = transforms.Compose([\n\u001b[32m      8\u001b[39m     transforms.ToTensor(),\n\u001b[32m      9\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m whole_dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../tiny-imagenet-200/train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m idx_datasets = np.arange(\u001b[38;5;28mlen\u001b[39m(whole_dataset))\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Subsampling\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[39m, in \u001b[36mImageFolder.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    327\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgs = \u001b[38;5;28mself\u001b[39m.samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[39m, in \u001b[36mDatasetFolder.__init__\u001b[39m\u001b[34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    140\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    147\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform=transform, target_transform=target_transform)\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     classes, class_to_idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     samples = \u001b[38;5;28mself\u001b[39m.make_dataset(\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.root,\n\u001b[32m    152\u001b[39m         class_to_idx=class_to_idx,\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m         allow_empty=allow_empty,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m.loader = loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[39m, in \u001b[36mDatasetFolder.find_classes\u001b[39m\u001b[34m(self, directory)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m    208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[32m    209\u001b[39m \n\u001b[32m    210\u001b[39m \u001b[33;03m        directory/\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m \u001b[33;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001b[39m, in \u001b[36mfind_classes\u001b[39m\u001b[34m(directory)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_classes\u001b[39m(directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[33;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     classes = \u001b[38;5;28msorted\u001b[39m(entry.name \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry.is_dir())\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m     43\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] El sistema no puede encontrar la ruta especificada: '../tiny-imagenet-200/train'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 5\n",
    "SAMPLE = 50000\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "whole_dataset = datasets.ImageFolder('../../tiny-imagenet-200/train', transform=transform)\n",
    "idx_datasets = np.arange(len(whole_dataset))\n",
    "\n",
    "# Subsampling\n",
    "\n",
    "subset = random.choices(idx_datasets, k=SAMPLE)\n",
    "train, test = train_test_split(subset)\n",
    "\n",
    "\n",
    "train = torch.utils.data.Subset(whole_dataset, train)\n",
    "test = torch.utils.data.Subset(whole_dataset, test)\n",
    "\n",
    "# test = datasets.ImageFolder('../../data/tiny-imagenet-200/test', transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fa3a6b8385d7",
   "metadata": {},
   "source": [
    "L'estructura ``ImageFolder`` de PyTorch és una classe de ``torchvision.datasets`` que permet carregar un conjunt de dades d'imatges estructurat en carpetes, on cada subcarpeta representa una classe. És útil per a projectes de classificació d'imatges, ja que facilita la lectura automàtica d'imatges i etiquetes a partir de la seva organització en el sistema de fitxers.\n",
    "\n",
    "### Estructura de carpetes\n",
    "L'estructura que requereix ``ImageFolder`` per funcionar és la següent:\n",
    "\n",
    "```\n",
    "dataset_root/\n",
    "├── class1/\n",
    "│   ├── image1.jpg\n",
    "│   ├── image2.jpg\n",
    "│   └── ...\n",
    "├── class2/\n",
    "│   ├── image1.jpg\n",
    "│   ├── image2.jpg\n",
    "│   └── ...\n",
    "└── classN/\n",
    "    ├── image1.jpg\n",
    "    ├── image2.jpg\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "On cada subcarpeta dins de dataset_root té el nom d'una classe, i dins de cada subcarpeta hi ha les imatges corresponents a aquella classe.\n",
    "\n",
    "#### Com funciona ImageFolder\n",
    "\n",
    "1. Etiquetes automàtiques: ImageFolder assigna una etiqueta numèrica a cada carpeta (classe) seguint l'ordre alfabètic dels noms de les carpetes.\n",
    "2. Transformacions: Pots afegir transformacions com ToTensor, Resize, Normalize, etc., per pre-processar les imatges en el moment de carregar-les.\n",
    "3. Dades i etiquetes: Cada vegada que crides un element del dataset, ImageFolder retorna una tupla (imatge, etiqueta).\n",
    "\n",
    "Aquest mètode és molt eficient per carregar i estructurar imatges per a tasques de classificació i facilita la integració amb models de PyTorch com AlexNet, ResNet, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0756ea88b51da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = next(iter(train_loader))\n",
    "print(img.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe645c3e13180bbe",
   "metadata": {},
   "source": [
    "## Definició de la xarxa: AlexNet i *Transfer learning*\n",
    "\n",
    "En aquesta pràctica aplicarem la tècnica de transfer learning amb la primera xarxa CNN moderna:\n",
    "- AlexNet. [ImageNet Classification with Deep Convolutional Neural Network, 2012](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf). La mida d'entrada de les imatges és de (227x227x3).Té prop de 60 milions de paràmetres entrenables.\n",
    "\n",
    "Pytorch ens permet emprar aquest tipus de xarxes de manera molt senzilla. [Més informació](https://pytorch.org/vision/stable/models.html). Si el model que cercam no es troba integrat dins la llibreria Pytorch és bastant probable que si la trobem a Huggingface.\n",
    "\n",
    "Descarregarem AlexNet i a analitzar-la. En aquest cas no només ens baixam la seva arquitectura, també els pesos resultants de l'entrenament.\n",
    "\n",
    "**Normalment els problems els resoldrem emprant models ja definits i preentrenats**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbbcc900043cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex = models.alexnet(weights=True)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Arquitectura AlexNet\")\n",
    "print(\"-\" * 50)\n",
    "print(alex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633321e56ea811ed",
   "metadata": {},
   "source": [
    "Podem accedir a una capa concreta pel seu nom o índex dins de l’estructura del model. Per exemple: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3f9f3c6064fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex.features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfdeded411a78f",
   "metadata": {},
   "source": [
    "El que nosaltres volem fer és emprar els pesos ja entrenats d'aquest model i aplicar-ho per resoldre un problema nou. Hi ha diverses maneres de realitzar la tècnica de ``Transfer Learning``. Les dues les hem explicades a la introducció, en aquest cas però emprarem el ``transfer learning`` pròpiament dit. L'element principal és congelar les capes de l'extractor de característiques. Per fer-ho empram les següents instruccions\n",
    "\n",
    "```\n",
    "for param in alex.features.parameters():\n",
    "   param.requires_grad = False\n",
    "\n",
    "```\n",
    "\n",
    "## Feina a fer:\n",
    "\n",
    "1. Carregar la xarxa AlexNet i congelar l'extractor de característiques.\n",
    "2. Definir un entorn seqüencial on implementarem el classificador de la xarxa.\n",
    "3. Realitzar un entrenament: comparar rendiment (accuracy) i nombre de paràmetres.\n",
    "4. Provar de guardar la vostra xarxa i tornar-la a carregar. Classificar una imatge del conjunt de test.\n",
    "\n",
    "**Nota**. Com veureu no us donam aquesta vegada el bucle d'entrenament, sigui com sigui podeu adaptar el vist a les sessions anteriors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc30616c65ed32c",
   "metadata": {},
   "source": [
    "## EXTRA: Com emprar la GPU per entrenar un model\n",
    "\n",
    "Un dels elements diferencials d'aquest model, respecte als que havíem vist fins ara, és la seva mida i, per tant, l'entrenament es torna impossible emprant __CPU__ directament. Per resoldre-ho hem d'emprar una **GPU**, a Google Colab disposam d'elles gratuïtament. Per fer-ho amb *Pytorch* hem de fer tres passes: \n",
    "\n",
    "1. Comprovar que hi ha una GPU disponible.\n",
    "2. Moure el model a GPU.\n",
    "3. Moure les dades a GPU.\n",
    "\n",
    "### Comprova si tenim una GPU disponible\n",
    "\n",
    "Primer de tot, cal verificar si hi ha una GPU disponible a l’entorn. Això es pot fer amb el següent codi:\n",
    "\n",
    "```python\n",
    "\n",
    "import torch\n",
    "\n",
    "is_cuda = torch.cuda.is_available() \n",
    "```\n",
    "\n",
    "Si la variable ``is_cuda`` és certa, llavors tens accés a una GPU. \n",
    "\n",
    "### Mou el model a la GPU\n",
    "\n",
    "En PyTorch, els models han d'estar explícitament en la GPU per poder fer servir la seva potència de càlcul. Si estàs carregant un model preentrenat (com AlexNet, ResNet, etc.), o si has definit el teu propi model, pots moure’l a la GPU amb ``.to(device)``, on device fa referència a la GPU.\n",
    "\n",
    "```python\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "```\n",
    "\n",
    "Això mou el model a la GPU (si està disponible). Si només tens una CPU, el model es mantindrà a la CPU.\n",
    "\n",
    "### Mou les dades a la GPU\n",
    "\n",
    "No només el model, sinó que també les dades (inputs) han d'estar a la GPU per fer les operacions més ràpides. Així, abans de fer servir les dades com a inputs del model, assegura't de moure-les al mateix device:\n",
    "\n",
    "```python\n",
    "\n",
    "# Exemple d'un batch de dades\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb385215b93e5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex = models.alexnet(weights=True)\n",
    "#Freezing the feature extractor\n",
    "for param in alex.features.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d1cb5781c192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex.classifier = nn.Sequential(\n",
    "    torch.nn.Linear(9216, 1024),\n",
    "    nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    torch.nn.Linear(512, 200),  # Ja que tenim 200 classes.\n",
    "    nn.Softmax(dim=1)\n",
    ")  # Ja que és multiclasse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac66732aeb2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3  # Hiperparàmetre\n",
    "optimizer = optim.Adam(alex.parameters(), lr=learning_rate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = alex.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b7419de56313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "running_loss = []\n",
    "running_acc = []\n",
    "\n",
    "running_test_loss = []\n",
    "running_test_acc_cnn = []\n",
    "\n",
    "for t in tqdm(range(EPOCHS), desc=\"Èpoques\"):\n",
    "    batch_loss = 0\n",
    "    batch_acc = 0\n",
    "\n",
    "    i_batch = 1\n",
    "    # Iteram els batches.\n",
    "    for i_batch, (x, y) in tqdm(enumerate(train_loader), desc=f\"Batches (Època {t + 1})\", leave=False):\n",
    "        alex.train()  # Posam el model a mode entranament.\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1. PREDICCIÓ\n",
    "        y_pred = alex(x.to(device))\n",
    "\n",
    "        # 2. CALCUL DE LA PÈRDUA\n",
    "        # Computa la pèrdua: l'error de predicció vs el valor correcte\n",
    "        # Es guarda la pèrdua en un array per futures visualitzacions\n",
    "\n",
    "        loss = loss_fn(y_pred, y.to(device))\n",
    "\n",
    "        #3. GRADIENT\n",
    "        alex.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Actualitza els pesos utilitzant l'algorisme d'actualització\n",
    "        #4. OPTIMITZACIO\n",
    "        with torch.no_grad():\n",
    "            optimizer.step()\n",
    "\n",
    "        # 5. EVALUAM EL MODEL\n",
    "        alex.eval()  # Mode avaluació de la xarxa\n",
    "\n",
    "        y_pred = alex(x.to(device))\n",
    "        batch_loss += (loss_fn(y_pred, y.to(device)).detach())\n",
    "\n",
    "        y_pred_class = torch.argmax(y_pred, dim=1)\n",
    "        batch_acc += accuracy_score(y, y_pred_class.detach().cpu().numpy())\n",
    "\n",
    "    running_loss.append(batch_loss / (i_batch + 1))\n",
    "    running_acc.append(batch_acc / (i_batch + 1))\n",
    "\n",
    "    batch_test_loss = 0\n",
    "    batch_test_acc = 0\n",
    "\n",
    "    alex.eval()\n",
    "    for i_batch, (x, y) in enumerate(test_loader):\n",
    "        y_pred = alex(x.to(device))\n",
    "        batch_test_loss += (loss_fn(y_pred, y.to(device)).detach())\n",
    "\n",
    "        y_pred_class = torch.argmax(y_pred, dim=1).detach().cpu().numpy()\n",
    "        batch_test_acc += accuracy_score(y, y_pred_class)\n",
    "\n",
    "    running_test_loss.append(batch_test_loss / (i_batch + 1))\n",
    "    running_test_acc_cnn.append(batch_test_acc / (i_batch + 1))\n",
    "    print(f\"Època {t + 1} finalitzada. \"\n",
    "          f\"Pèrdua entrenament: {running_loss[-1]:.4f}, \"\n",
    "          f\"Precisió entrenament: {running_acc[-1]:.4f}, \"\n",
    "          f\"Pèrdua test: {running_test_loss[-1]:.4f}, \"\n",
    "          f\"Precisió test: {running_test_acc_cnn[-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
